{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:33.345629Z",
     "start_time": "2024-05-23T07:23:33.342291Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from folium import plugins"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:37.086287Z",
     "start_time": "2024-05-23T07:23:37.083502Z"
    }
   },
   "source": [
    "# for a wider display, making it easier to view large DataFrames without line breaks.\n",
    "pd.set_option('display.width', 1000)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:38.003902Z",
     "start_time": "2024-05-23T07:23:37.995494Z"
    }
   },
   "source": [
    "data_hanze = pd.read_csv('data/hanze.csv')\n",
    "print(data_hanze.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year Country name  Start date    End date   Type                           Regions affected (v2021)             Cause                       References\n",
      "0  1453  1979  Switzerland  1979-06-01  1979-06-02  Flash                                        CH061;CH065  Extreme rainfall             Rothlisberger (1991)\n",
      "1  6017  1981  Switzerland  1981-07-10  1981-07-12  River                                              CH033    Heavy rainfall  Zeller and Röthlisberger (1982)\n",
      "2  1454  1984  Switzerland  1984-07-24  1984-07-25  Flash  CH021;CH031;CH040;CH052;CH053;CH054;CH055;CH06...  Extreme rainfall             Rothlisberger (1991)\n",
      "3  1455  1985  Switzerland  1985-07-04  1985-07-05  Flash                                        CH021;CH022  Extreme rainfall             Rothlisberger (1991)\n",
      "4  6019  1986  Switzerland  1986-05-23  1986-05-24  Flash                                              CH021  Extreme rainfall       Sturmarchiv Schweiz (2022)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Basic Filtering\n",
    "\n",
    "- Filter the data to include only rows from switzerland.\n",
    "- Limit the time period to 1979-2023."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:40.728105Z",
     "start_time": "2024-05-23T07:23:40.722598Z"
    }
   },
   "source": [
    "# Filter the data to include only rows where the 'Country name' is 'Switzerland'\n",
    "data_hanze_ch = data_hanze[data_hanze['Country name'] == 'Switzerland']\n",
    "\n",
    "# Further filter the data to include only rows where the 'Year' is between 1979 and 2023 (inclusive)\n",
    "data_hanze_ch = data_hanze_ch[(data_hanze_ch['Year'] >= 1979) & (data_hanze_ch['Year'] <= 2023)]\n",
    "\n",
    "# Print the first five rows of the filtered DataFrame to check the result\n",
    "print(data_hanze_ch.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year Country name  Start date    End date   Type                           Regions affected (v2021)             Cause                       References\n",
      "0  1453  1979  Switzerland  1979-06-01  1979-06-02  Flash                                        CH061;CH065  Extreme rainfall             Rothlisberger (1991)\n",
      "1  6017  1981  Switzerland  1981-07-10  1981-07-12  River                                              CH033    Heavy rainfall  Zeller and Röthlisberger (1982)\n",
      "2  1454  1984  Switzerland  1984-07-24  1984-07-25  Flash  CH021;CH031;CH040;CH052;CH053;CH054;CH055;CH06...  Extreme rainfall             Rothlisberger (1991)\n",
      "3  1455  1985  Switzerland  1985-07-04  1985-07-05  Flash                                        CH021;CH022  Extreme rainfall             Rothlisberger (1991)\n",
      "4  6019  1986  Switzerland  1986-05-23  1986-05-24  Flash                                              CH021  Extreme rainfall       Sturmarchiv Schweiz (2022)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Missing Values\n",
    "\n",
    "Find any missing values in the dataset and determine the total number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:43.408914Z",
     "start_time": "2024-05-23T07:23:43.405128Z"
    }
   },
   "source": [
    "#Missing values\n",
    "missing = data_hanze_ch.isnull().sum()\n",
    "total_missing = missing.sum()\n",
    "\n",
    "print(missing)\n",
    "print(total_missing)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                          0\n",
      "Year                        0\n",
      "Country name                0\n",
      "Start date                  0\n",
      "End date                    0\n",
      "Type                        0\n",
      "Regions affected (v2021)    0\n",
      "Cause                       0\n",
      "References                  0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Remove unnecessary columns from the dataset to focus on the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:23:45.688390Z",
     "start_time": "2024-05-23T07:23:45.600191Z"
    }
   },
   "source": [
    "data_hanze_ch = data_hanze_ch.drop(columns=['Country code'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Area flooded'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Regions affected (v2010)'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Persons affected'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Fatalities'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Losses (nominal value)'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Flood source'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Notes'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Changes'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Losses (2020 euro)'])\n",
    "data_hanze_ch = data_hanze_ch.drop(columns=['Losses (original currency)'])\n",
    "\n",
    "print(data_hanze_ch.head())"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Country code'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_hanze_ch \u001B[38;5;241m=\u001B[39m \u001B[43mdata_hanze_ch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCountry code\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m data_hanze_ch \u001B[38;5;241m=\u001B[39m data_hanze_ch\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mArea flooded\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m data_hanze_ch \u001B[38;5;241m=\u001B[39m data_hanze_ch\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRegions affected (v2010)\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/code/cdk1/venv/lib/python3.9/site-packages/pandas/core/frame.py:5581\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[1;32m   5434\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5435\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5442\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5443\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5445\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5446\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5579\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5583\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5587\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5588\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/cdk1/venv/lib/python3.9/site-packages/pandas/core/generic.py:4788\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4786\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4788\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/code/cdk1/venv/lib/python3.9/site-packages/pandas/core/generic.py:4830\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4828\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4829\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4830\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4831\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4833\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/code/cdk1/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:7070\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   7068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   7069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 7070\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   7071\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   7072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['Country code'] not found in axis\""
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Review again, if there are any missing values."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Missing values\n",
    "missing = data_hanze_ch.isnull().sum()\n",
    "total_missing = missing.sum()\n",
    "\n",
    "print(missing)\n",
    "print(total_missing)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Store the cleaned data in a new CSV file."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_hanze_ch.to_csv('data/hanze_ch.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the csv file with the region codes. The region codes file contains the mapping betwen the region codes in the hanze csv and coordinates."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "regions = pd.read_csv('data/source/regioncodes.csv')\n",
    "print(regions.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter the regions to include only the regions in Switzerland."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "regions_ch = regions[regions['Code'].str[:2] == 'CH']\n",
    "\n",
    "print(regions_ch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Coordinate mapping\n",
    "\n",
    "- Use the geopy library to retrieve the coordinates (latitude and longitude) of each canton in Switzerland.\n",
    "- Nominatim is a powerful open-source geocoding service provided by the OpenStreetMap project. It allows developers to convert human-readable addresses into precise geographic coordinates and vice versa.\n",
    "- The RateLimiter class is used to limit the number of requests sent to the geocoding service to avoid running into rate limits of the OSM server.\n",
    "- The get_coordinates function retrieves the coordinates of a canton using the geocode function of the geolocator."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize the Geolocator with a user agent of your choice\n",
    "geolocator = Nominatim(user_agent=\"my_app\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Function to retrieve the coordinates (latitude and longitude) of a canton\n",
    "def get_coordinates(kanton_name):\n",
    "    location = geocode(kanton_name)\n",
    "    return (location.latitude, location.longitude) if location else (None, None)\n",
    "\n",
    "# Perform geocoding for each canton and store the coordinates directly in the 'Coordinates' column\n",
    "regions_ch['Coordinates'] = regions_ch['Name'].apply(get_coordinates)\n",
    "\n",
    "print(regions_ch.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a dictionary to map codes to coordinates\n",
    "code_to_coords = dict(zip(regions_ch['Code'], regions_ch['Coordinates']))\n",
    "\n",
    "# Function to replace codes with coordinates\n",
    "def replace_codes_with_coords(code_list):\n",
    "    coords_list = [code_to_coords.get(code.strip()) for code in code_list.split(';') if code.strip() in code_to_coords]\n",
    "    return coords_list\n",
    "\n",
    "# Apply the function to the 'Regions affected (v2021)' column\n",
    "data_hanze_ch['Regions affected (v2021)'] = data_hanze_ch['Regions affected (v2021)'].apply(replace_codes_with_coords)\n",
    "\n",
    "print(data_hanze_ch.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Store the updated dataset with the coordinates on disk."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_hanze_ch.to_csv('data/hanze_ch.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Missing values\n",
    "missing = data_hanze_ch.isnull().sum()\n",
    "total_missing = missing.sum()\n",
    "\n",
    "print(missing)\n",
    "print(total_missing)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Exploration\n",
    "- Analyze the number of events per year."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count the number of events per year\n",
    "year_counts = data_hanze_ch['Year'].value_counts().sort_index()   # Sort by year for better visualization\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 8))  \n",
    "plt.bar(year_counts.index.astype(str), year_counts.values, color='magenta')  # Choose a color for the bars\n",
    "plt.xlabel('Jahr') \n",
    "plt.ylabel('Anzahl der Ereignisse')  \n",
    "plt.title('Anzahl der Ereignisse pro Jahr')  \n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if necessary\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyze the number of events per type\n",
    "- In switzerland there are only two types of events: River and Flash."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count the number of events per type\n",
    "type_counts = data_hanze_ch['Type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "plt.bar(type_counts.index, type_counts.values, color=['blue', 'green'])  \n",
    "plt.xlabel('Typ des Ereignisses')  \n",
    "plt.ylabel('Anzahl der Ereignisse')  \n",
    "plt.title('Summe der Ereignistypen River und Flash') \n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Explore the causes of events."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count the number of events per cause\n",
    "cause_counts = data_hanze_ch['Cause'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 8))  \n",
    "plt.bar(cause_counts.index, cause_counts.values, color='cyan')  \n",
    "plt.xlabel('Ursache des Ereignisses')\n",
    "plt.ylabel('Anzahl der Ereignisse')  \n",
    "plt.title('Häufigkeit der verschiedenen Ursachen von Ereignissen')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a cross-tabulation between two categorical variables\n",
    "crosstab = pd.crosstab(data_hanze_ch['Type'], data_hanze_ch['Cause'])\n",
    "\n",
    "# Perform the Chi-Square test of independence\n",
    "chi2, p_value, dof, expected = chi2_contingency(crosstab)\n",
    "print(f\"Chi-Quadrat-Wert: {chi2}, p-Wert: {p_value}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\tCorrelation Coefficient Values:\n",
    "-  1: Perfect positive correlation. As one variable increases, the other variable also increases.\n",
    "-  0: No correlation. There is no linear relationship between the variables.\n",
    "-  -1: Perfect negative correlation. As one variable increases, the other variable decreases.\n",
    "\n",
    "#### 2.\tDiagonal Elements (e.g., ID with ID):\n",
    "-  he diagonal elements are all 1 because each variable is perfectly correlated with itself.\n",
    "\n",
    "#### 3.\tOff-Diagonal Elements:\n",
    "-  D with Year: The correlation coefficient is 0.19. This indicates a weak positive correlation, meaning that as Year increases, ID tends to increase slightly.\n",
    "-  ID with Duration: The correlation coefficient is -0.15. This indicates a weak negative correlation, meaning that as ID increases, Duration tends to decrease slightly.\n",
    "-  Year with Duration: The correlation coefficient is 0.19. This indicates a weak positive correlation, meaning that as Year increases, Duration tends to increase slightly.\n",
    "\n",
    "#### 4.\tColor Coding:\n",
    "-  The colors range from blue (negative correlation) to red (positive correlation).\n",
    "-  Dark red (1.0) indicates a perfect positive correlation.\n",
    "-  Dark blue (-1.0) would indicate a perfect negative correlation (though not present here).\n",
    "-  Lighter shades closer to the middle of the color spectrum indicate weaker correlations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert the 'Start date' and 'End date' columns to datetime\n",
    "data_hanze_ch['Start date'] = pd.to_datetime(data_hanze_ch['Start date'], format='%Y-%m-%d')\n",
    "data_hanze_ch['End date'] = pd.to_datetime(data_hanze_ch['End date'], format='%Y-%m-%d')\n",
    "\n",
    "# Calculate the duration of events in days\n",
    "data_hanze_ch['Duration'] = (data_hanze_ch['End date'] - data_hanze_ch['Start date']).dt.days\n",
    "\n",
    "# Isolate the numeric columns for descriptive statistics\n",
    "numeric_columns = data_hanze_ch.select_dtypes(include=[np.number])  # Ensure numpy is imported\n",
    "print(numeric_columns.describe())\n",
    "\n",
    "# Create a correlation matrix only for numeric variables\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Korrelationsmatrix der numerischen Variablen')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert the date values into datetime objects\n",
    "data_hanze_ch['Start date'] = pd.to_datetime(data_hanze_ch['Start date'], format='%Y-%m-%d')\n",
    "data_hanze_ch['End date'] = pd.to_datetime(data_hanze_ch['End date'], format='%Y-%m-%d')\n",
    "\n",
    "# Calculate the duration in days\n",
    "data_hanze_ch[\"Duration\"] = (data_hanze_ch[\"End date\"] - data_hanze_ch[\"Start date\"]).dt.days\n",
    "\n",
    "# Preparation of the data for the regression\n",
    "X = data_hanze_ch[\"Year\"].values.reshape(-1, 1) \n",
    "y = data_hanze_ch[\"Duration\"].values  \n",
    "\n",
    "# Apply linear regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "# Predictions for the line\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "# Create plot\n",
    "plt.scatter(X, y, color='blue', label='Ereignisdauer')\n",
    "plt.plot(X, y_pred, color='red', label='Lineare Regression')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Duration (days)\")\n",
    "plt.title(\"Lineare Regression der Ereignisdauer über Jahre\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = pd.read_csv('data/df_ch.csv', delimiter=';')\n",
    "\n",
    "print(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Completeness:** Check for gaps in the data, especially in historical records"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Missing values\n",
    "missing = data.isnull().sum()\n",
    "total_missing = missing.sum()\n",
    "\n",
    "print(missing)\n",
    "print(total_missing)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data['DAY'] = pd.to_datetime(data['DAY'], format='%Y%m%d')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index, data.isnull(), 'o', markersize=2)\n",
    "plt.title('Fehlende Daten im Zeitverlauf')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Fehlt Daten? (Ja=1, Nein=0)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Quality:** Identify possible errors or anomalies in the data (e.g., extremely high or low values that are outside of plausible ranges)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "df = data\n",
    "\n",
    "# Boxplots for numeric columns\n",
    "numerical_columns = [\"TEMPERATURE_MAX\", \"TEMPERATURE_MIN\", \"WINDSPEED\", \"VAPOURPRESSURE\", \"PRECIPITATION\", \"ET0\"]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(y=df[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Histogram for numeric columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[column], bins=30, kde=True)\n",
    "    plt.title(f'Histogram of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scatterplots between temperature and other variables\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    if column != \"TEMPERATURE_MAX\" and column != \"TEMPERATURE_MIN\":\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.scatterplot(x=df[\"TEMPERATURE_MAX\"], y=df[column], alpha=0.2)\n",
    "        plt.title(f'Scatterplot of TEMPERATURE_MAX vs {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correlation matrix visualizes the relationships between various meteorological variables in your dataset: TEMPERATURE_MAX, TEMPERATURE_MIN, WINDSPEED, VAPOURPRESSURE, PRECIPITATION, and ETO. The numbers and colors indicate the strength and direction of the correlations between these variables. Here is how to interpret the matrix:\n",
    "\n",
    "#### Correlation Coefficient Values\n",
    "-  1: Perfect positive correlation. As one variable increases, the other variable also increases.\n",
    "-  0: No correlation. There is no linear relationship between the variables.\n",
    "-  -1: Perfect negative correlation. As one variable increases, the other variable decreases.\n",
    "\n",
    "#### Diagonal Elements\n",
    "-  The diagonal elements are all 1 because each variable is perfectly correlated with itself.\n",
    "\n",
    "#### Off-Diagonal Elements\n",
    "-  TEMPERATURE_MAX with TEMPERATURE_MIN: The correlation coefficient is 0.89, indicating a strong positive correlation. This means higher maximum temperatures are associated with higher minimum temperatures.\n",
    "-  TEMPERATURE_MAX with VAPOURPRESSURE: The correlation coefficient is 0.86, indicating a strong positive correlation.\n",
    "-  TEMPERATURE_MAX with ETO: The correlation coefficient is 0.84, indicating a strong positive correlation.\n",
    "-  TEMPERATURE_MIN with VAPOURPRESSURE: The correlation coefficient is 0.91, indicating a very strong positive correlation.\n",
    "-  TEMPERATURE_MIN with ETO: The correlation coefficient is 0.70, indicating a strong positive correlation.\n",
    "-  VAPOURPRESSURE with ETO: The correlation coefficient is 0.65, indicating a moderate positive correlation.\n",
    "-  WINDSPEED with other variables: The correlations are generally weak to moderate, with the strongest being a negative correlation of -0.25 with TEMPERATURE_MAX.\n",
    "-  PRECIPITATION with other variables: The correlations are generally weak, with the strongest being 0.15 with VAPOURPRESSURE.\n",
    "\n",
    "#### Color Coding\n",
    "-  Red (close to 1): Strong positive correlation.\n",
    "-  Blue (close to -1): Strong negative correlation.\n",
    "-  Lighter shades closer to the middle of the color spectrum (closer to 0): Weaker correlations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Heatmap of correlations between numerical variables\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df[numerical_columns].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Heatmap of Correlations')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary Statistics:** Mean, median, mode, minimum, and maximum of precipitation amounts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate the summarised statistics for the precipitation quantities (Precipitation)\n",
    "\n",
    "mean_precipitation = df['PRECIPITATION'].mean()\n",
    "median_precipitation = df['PRECIPITATION'].median()\n",
    "mode_precipitation = df['PRECIPITATION'].mode()[0] \n",
    "min_precipitation = df['PRECIPITATION'].min()\n",
    "max_precipitation = df['PRECIPITATION'].max()\n",
    "\n",
    "print(f\"Mean of Precipitation: {mean_precipitation}\")\n",
    "print(f\"Median of Precipitation: {median_precipitation}\")\n",
    "print(f\"Mode of Precipitation: {mode_precipitation}\")\n",
    "print(f\"Minimum of Precipitation: {min_precipitation}\")\n",
    "print(f\"Maximum of Precipitation: {max_precipitation}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variance and Standard Deviation:** How much does precipitation vary?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "variance_precipitation = df['PRECIPITATION'].var()\n",
    "std_dev_precipitation = df['PRECIPITATION'].std()\n",
    "\n",
    "# Output of variance and standard deviation\n",
    "print(f\"Variance of Precipitation: {variance_precipitation}\")\n",
    "print(f\"Standard Deviation of Precipitation: {std_dev_precipitation}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visual Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series Analysis:** Visualization of precipitation data over time to detect trends, seasonal patterns, and anomalies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df['DATE'] = pd.to_datetime(df['DAY'], format='%Y%m%d')\n",
    "\n",
    "# Set the date as an index\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Time series plot for precipitation data\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['PRECIPITATION'], color='blue', label='Daily Precipitation')\n",
    "plt.title('Time Series of Daily Precipitation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate rolling mean and rolling standard deviation (e.g. 30-day window)\n",
    "rolling_mean = df['PRECIPITATION'].rolling(window=30).mean()\n",
    "rolling_std = df['PRECIPITATION'].rolling(window=30).std()\n",
    "\n",
    "# Plot mit Rolling Mean und Rolling Standard Deviation\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['PRECIPITATION'], color='blue', label='Daily Precipitation')\n",
    "plt.plot(rolling_mean, color='red', label='30-Day Rolling Mean')\n",
    "plt.plot(rolling_std, color='green', label='30-Day Rolling Std Dev')\n",
    "plt.title('Time Series of Daily Precipitation with Rolling Statistics')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate and plot seasonal averages\n",
    "df['Year'] = df.index.year\n",
    "df['Month'] = df.index.month\n",
    "monthly_mean = df.groupby(['Year', 'Month'])['PRECIPITATION'].mean().unstack()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(monthly_mean, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "plt.title('Monthly Average Precipitation')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Year')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Histograms:** Distribution of precipitation intensities."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Histogram for precipitation intensities\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['PRECIPITATION'], bins=30, kde=True)\n",
    "plt.title('Histogram of Precipitation Intensities')\n",
    "plt.xlabel('Precipitation (mm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Histogram for precipitation intensities without values of 0\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[df['PRECIPITATION'] > 0]['PRECIPITATION'], bins=30, kde=True)\n",
    "plt.title('Histogram of Non-Zero Precipitation Intensities')\n",
    "plt.xlabel('Precipitation (mm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Boxplots:** To visualize the distribution of precipitation amounts and identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setting the figure size for better visibility\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating a boxplot for the precipitation data\n",
    "sns.boxplot(y=df['PRECIPITATION'])\n",
    "\n",
    "plt.title('Boxplot of Precipitation Amounts')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setting the figure size for better visibility\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating a boxplot for the precipitation data with a limited y-axis\n",
    "sns.boxplot(y=df['PRECIPITATION'])\n",
    "\n",
    "plt.title('Boxplot of Precipitation Amounts (Zoomed In)')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "\n",
    "# Limiting the y-axis to focus on the central part of the data\n",
    "plt.ylim(-1, 10)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x=df['Year'], y=df['PRECIPITATION'])\n",
    "plt.title('Boxplot of Precipitation Amounts by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x=df['Year'], y=df['PRECIPITATION'])\n",
    "plt.title('Boxplot of Precipitation Amounts by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Limiting the y-axis to focus on the central part of the data\n",
    "plt.ylim(-1, 12)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Boxplot for precipitation amounts by month\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x=df['Month'], y=df['PRECIPITATION'])\n",
    "plt.title('Boxplot of Precipitation Amounts by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Boxplot for precipitation amounts by month\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x=df['Month'], y=df['PRECIPITATION'])\n",
    "plt.title('Boxplot of Precipitation Amounts by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "\n",
    "# Limiting the y-axis to focus on the central part of the data\n",
    "plt.ylim(-1, 12)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Map-based Visualizations:** Geographic representation of precipitation data and flood areas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display, IFrame\n",
    "import ast\n",
    "\n",
    "# Extract precipitation data\n",
    "precipitation_data = data[['LATITUDE', 'LONGITUDE', 'PRECIPITATION']].values.tolist()\n",
    "\n",
    "# Create a map centered on Switzerland\n",
    "map_center = [46.8182, 8.2275]  # Center of Switzerland\n",
    "m = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "# Add precipitation data as a heatmap\n",
    "HeatMap(precipitation_data, radius=10).add_to(m)\n",
    "\n",
    "# Display the map inline in the notebook\n",
    "m"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Initialize a map centered around Switzerland\n",
    "m = folium.Map(location=[46.8182, 8.2275], zoom_start=8)\n",
    "\n",
    "# Add HeatMap for each set of coordinates in 'Regions affected (v2021)'\n",
    "for regions in data_hanze_ch['Regions affected (v2021)']:\n",
    "    HeatMap(regions, radius=10, blur=15, gradient={0.4: 'blue', 0.65: 'lime', 1: 'red'}).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
